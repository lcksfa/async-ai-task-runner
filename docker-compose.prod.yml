# ğŸ­ Async AI Task Runner - ç”Ÿäº§ç¯å¢ƒDocker Composeé…ç½®
# ä¼˜åŒ–äº†å®‰å…¨æ€§å’Œæ€§èƒ½çš„ç”Ÿäº§çº§é…ç½®

version: '3.8'

services:
  # ğŸ—„ï¸ PostgreSQLæ•°æ®åº“æœåŠ¡ (ç”Ÿäº§é…ç½®)
  postgres:
    image: postgres:16-alpine
    container_name: async_ai_postgres_prod
    restart: always
    environment:
      POSTGRES_DB: task_runner
      POSTGRES_USER: taskuser
      # å¯†ç åº”ä»ç¯å¢ƒå˜é‡æˆ–Docker secretsè·å–
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # ç”Ÿäº§ç¯å¢ƒåˆå§‹åŒ–è„šæœ¬
      - ./docker/postgres/prod-init:/docker-entrypoint-initdb.d
    networks:
      - async_ai_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U taskuser -d task_runner"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ğŸ”´ RedisæœåŠ¡ (ç”Ÿäº§é…ç½®)
  redis:
    image: redis:7-alpine
    container_name: async_ai_redis_prod
    restart: always
    command: >
      redis-server
      /usr/local/etc/redis/redis.conf
      --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./docker/redis/prod-redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - async_ai_network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ğŸŒ Webåº”ç”¨æœåŠ¡ (ç”Ÿäº§é…ç½®)
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: async_ai_web_prod
    restart: always
    environment:
      # æ•°æ®åº“é…ç½®
      DATABASE_URL: postgresql+asyncpg://taskuser:${POSTGRES_PASSWORD}@postgres:5432/task_runner

      # Redisé…ç½® (å¸¦å¯†ç )
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/1
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2

      # åº”ç”¨é…ç½® (å¿…é¡»ä»ç¯å¢ƒå˜é‡æä¾›)
      SECRET_KEY: ${SECRET_KEY}
      DEBUG: false
      ENVIRONMENT: production

      # AIæœåŠ¡é…ç½®
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}

      # CORSé…ç½® (ç”Ÿäº§ç¯å¢ƒé™åˆ¶åŸŸ)
      CORS_ORIGINS: ${CORS_ORIGINS}

      # æ—¥å¿—çº§åˆ«
      LOG_LEVEL: INFO
    networks:
      - async_ai_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # âš™ï¸ WorkeræœåŠ¡ (ç”Ÿäº§é…ç½®)
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    restart: always
    environment:
      DATABASE_URL: postgresql+asyncpg://taskuser:${POSTGRES_PASSWORD}@postgres:5432/task_runner
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/0
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/1
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      SECRET_KEY: ${SECRET_KEY}
      DEBUG: false
      ENVIRONMENT: production
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      WORKER_CONCURRENCY: ${WORKER_CONCURRENCY:-2}
      LOG_LEVEL: INFO
    networks:
      - async_ai_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ğŸŒº Flowerç›‘æ§æœåŠ¡ (ç”Ÿäº§é…ç½®)
  flower:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: async_ai_flower_prod
    restart: always
    environment:
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/1
      CELERY_RESULT_BACKEND: redis://:${REDIS_PASSWORD}@redis:6379/2
      FLOWER_BASIC_AUTH_USER: ${FLOWER_USER}
      FLOWER_BASIC_AUTH_PASSWORD: ${FLOWER_PASSWORD}
    networks:
      - async_ai_network
    depends_on:
      - redis
    command: ["uv", "run", "celery", "-A", "app.worker.app", "flower", "--port=5555", "--basic_auth=${FLOWER_USER}:${FLOWER_PASSWORD}"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

networks:
  async_ai_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.21.0.0/16