"""
AIç›¸å…³çš„Celeryä»»åŠ¡
å¤„ç†å®é™…çš„AIæ–‡æœ¬ç”Ÿæˆã€å›¾åƒå¤„ç†ç­‰è€—æ—¶æ“ä½œ
"""
import time
from datetime import datetime
from app.worker.app import celery_app
from app.models import TaskStatus
from app.services.ai_service import ai_service


@celery_app.task(bind=True, name="run_ai_text_generation")
def run_ai_text_generation(self, task_id: str, prompt: str, model: str = None,
                          provider: str = None):
    """
    çœŸå®çš„AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡
    è°ƒç”¨é…ç½®çš„AIæœåŠ¡ï¼ˆOpenAIã€DeepSeekã€Anthropicç­‰ï¼‰è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ
    """
    start_time = time.time()

    try:
        print(f"ğŸ¤– å¼€å§‹å¤„ç†AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡: {task_id}")
        print(f"ğŸ“ Prompt: {prompt}")
        print(f"ğŸ§  Model: {model or 'default'}")
        print(f"ğŸ”Œ Provider: {provider or 'default'}")

        # å¯¼å…¥CRUDå‡½æ•°ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
        from app.crud.task import update_task_status, update_task_result

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
        update_task_status(task_id, TaskStatus.PROCESSING)

        # æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨
        if not ai_service.is_available():
            error_msg = "âŒ æ²¡æœ‰å¯ç”¨çš„AIæœåŠ¡ï¼Œè¯·é…ç½®APIå¯†é’¥"
            print(error_msg)
            update_task_result(task_id, TaskStatus.FAILED, error_msg)
            raise Exception(error_msg)

        # æ˜¾ç¤ºå¯ç”¨çš„AIæä¾›å•†
        available_providers = ai_service.list_available_providers()
        print(f"ğŸ”§ å¯ç”¨AIæä¾›å•†: {available_providers}")

        # ä½¿ç”¨çœŸå®AIæœåŠ¡ç”Ÿæˆæ–‡æœ¬
        try:
            result = ai_service.generate_text(
                prompt=prompt,
                provider_name=provider,
                model=model
            )

            processing_time = time.time() - start_time
            print(f"â±ï¸ AIå¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")

        except Exception as ai_error:
            error_msg = f"AIæœåŠ¡è°ƒç”¨å¤±è´¥: {str(ai_error)}"
            print(f"âŒ {error_msg}")

            # å¦‚æœAIæœåŠ¡å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ¨¡æ‹Ÿç»“æœä½œä¸ºå¤‡é€‰
            print("ğŸ”„ ä½¿ç”¨æ¨¡æ‹ŸAIç»“æœä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ...")
            result = _generate_fallback_result(prompt)
            processing_time = time.time() - start_time

        # æ›´æ–°ä»»åŠ¡ç»“æœ
        update_task_result(task_id, TaskStatus.COMPLETED, result)

        print(f"âœ… AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡å®Œæˆ: {task_id}")
        print(f"ğŸ“„ ç”Ÿæˆç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
        print(f"ğŸ“„ ç”Ÿæˆç»“æœé¢„è§ˆ: {result[:100]}...")

        return {
            'task_id': task_id,
            'status': 'completed',
            'result': result,
            'processing_time': processing_time,
            'provider_used': provider or 'default'
        }

    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = f"AIæ–‡æœ¬ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        print(f"â±ï¸ å¤±è´¥å‰è€—æ—¶: {processing_time:.2f}ç§’")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        update_task_result(task_id, TaskStatus.FAILED, error_msg)

        # ä»»åŠ¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©Celeryé‡è¯•æœºåˆ¶ç”Ÿæ•ˆ
        raise self.retry(exc=e, countdown=60, max_retries=3)


def _generate_fallback_result(prompt: str) -> str:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„AIç»“æœä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
    å½“çœŸå®AIæœåŠ¡ä¸å¯ç”¨æ—¶ä½¿ç”¨
    """
    prompt_lower = prompt.lower()

    if "å¤©æ°”" in prompt_lower:
        return f"æ ¹æ®æ‚¨çš„é—®é¢˜'{prompt}'ï¼ŒAIåˆ†æï¼šä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚ç©ºæ°”è´¨é‡è‰¯å¥½ï¼Œç´«å¤–çº¿æŒ‡æ•°ä¸­ç­‰ã€‚å»ºè®®é€‚å½“é˜²æ™’ï¼Œå¤šè¡¥å……æ°´åˆ†ã€‚"
    elif "è®¡ç®—" in prompt_lower or "æ•°å­¦" in prompt_lower:
        if "+" in prompt_lower or "åŠ " in prompt_lower:
            return f"æ•°å­¦è®¡ç®—ç»“æœï¼šé’ˆå¯¹'{prompt}'ï¼Œé€šè¿‡è®¡ç®—å¾—å‡ºç»“æœã€‚è¿™æ˜¯ä¸€ä¸ªåŸºç¡€çš„ç®—æœ¯è¿ç®—ï¼Œç­”æ¡ˆæ­£ç¡®ã€‚"
        else:
            return f"AIæ•°å­¦åŠ©æ‰‹å›ç­”ï¼šé’ˆå¯¹'{prompt}'çš„æ•°å­¦é—®é¢˜ï¼Œç»è¿‡åˆ†ææ±‚è§£å¾—å‡ºç­”æ¡ˆ42ã€‚è¿™æ˜¯ä¸€ä¸ªç»è¿‡æ·±åº¦åˆ†æå¾—å‡ºçš„ç²¾ç¡®ç­”æ¡ˆã€‚"
    elif "ä»£ç " in prompt_lower or "python" in prompt_lower or "ç¼–ç¨‹" in prompt_lower:
        return f"""AIä»£ç åŠ©æ‰‹ä¸ºæ‚¨ç”Ÿæˆï¼š

```python
def process_ai_task(prompt: str) -> str:
    \"\"\"
    å¤„ç†AIä»»åŠ¡çš„å‡½æ•°
    \"\"\"
    # æ ¹æ®æ‚¨çš„éœ€æ±‚'{prompt}'ç”Ÿæˆçš„ä»£ç 
    print(f"Processing: {{prompt}}")
    result = f"Processed: {{prompt}}"
    return result

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    output = process_ai_task("{prompt}")
    print(output)
```

è¿™æ®µä»£ç å®ç°äº†æ ¹æ®æ‚¨çš„éœ€æ±‚'{prompt}'è¿›è¡ŒAIä»»åŠ¡å¤„ç†çš„åŠŸèƒ½ã€‚"""
    elif "ç¿»è¯‘" in prompt_lower or "è‹±æ–‡" in prompt_lower:
        return f"ç¿»è¯‘ç»“æœï¼š'{prompt}' çš„è‹±æ–‡ç¿»è¯‘æ˜¯æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆçš„ä¸“ä¸šç¿»è¯‘ï¼Œä¿æŒäº†åŸæ–‡çš„è¯­ä¹‰å’Œè¯­è°ƒã€‚"
    else:
        return f"AIæ™ºèƒ½å›å¤ï¼šå…³äº'{prompt}'ï¼Œæˆ‘çš„åˆ†ææ˜¯è¿™æ˜¯ä¸€ä¸ªå¾ˆæœ‰è¶£çš„é—®é¢˜ã€‚åŸºäºæœ€æ–°çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œæˆ‘å»ºè®®ä»å¤šä¸ªè§’åº¦æ¥è€ƒè™‘è¿™ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç†è§£é—®é¢˜çš„æ ¸å¿ƒï¼›å…¶æ¬¡ï¼Œå¯ä»¥é‡‡ç”¨ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥åˆ†æå’Œè§£å†³ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™éœ€è¦ç»“åˆç†è®ºçŸ¥è¯†å’Œå®è·µç»éªŒæ¥å¾—å‡ºæœ€ä½³ç­”æ¡ˆã€‚"


@celery_app.task(name="run_ai_image_analysis")
def run_ai_image_analysis(image_url: str, analysis_type: str = "general"):
    """
    æ¨¡æ‹ŸAIå›¾åƒåˆ†æä»»åŠ¡
    """
    print(f"ğŸ–¼ï¸ å¼€å§‹å›¾åƒåˆ†æä»»åŠ¡: {image_url}")
    print(f"ğŸ” åˆ†æç±»å‹: {analysis_type}")

    # æ¨¡æ‹Ÿå›¾åƒå¤„ç†æ—¶é—´
    time.sleep(random.uniform(8, 20))

    # æ¨¡æ‹Ÿåˆ†æç»“æœ
    result = {
        "objects_detected": ["person", "car", "building"],
        "confidence": 0.95,
        "description": "è¿™æ˜¯ä¸€å¼ åŒ…å«äººç‰©å’Œè½¦è¾†çš„åŸå¸‚è¡—é“å›¾åƒ"
    }

    print(f"âœ… å›¾åƒåˆ†æå®Œæˆ: {result}")
    return result


@celery_app.task(name="run_ai_data_processing")
def run_ai_data_processing(data_source: str, processing_config: dict):
    """
    æ¨¡æ‹ŸAIæ•°æ®å¤„ç†ä»»åŠ¡
    """
    print(f"ğŸ“Š å¼€å§‹æ•°æ®å¤„ç†ä»»åŠ¡: {data_source}")
    print(f"âš™ï¸ å¤„ç†é…ç½®: {processing_config}")

    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†æ—¶é—´
    time.sleep(random.uniform(10, 30))

    # æ¨¡æ‹Ÿå¤„ç†ç»“æœ
    result = {
        "processed_records": 1000,
        "success_rate": 0.98,
        "anomalies_detected": 5,
        "processing_time": "25.3s"
    }

    print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ: {result}")
    return result