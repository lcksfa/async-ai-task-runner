# Async AI Task Runner é¡¹ç›®å®æ–½æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®åç§°**: Async AI Task Runner
**é¡¹ç›®ç±»å‹**: å¼‚æ­¥AIä»»åŠ¡å¤„ç†å¹³å°
**æŠ€æœ¯æ ˆ**: FastAPI + Celery + Redis + PostgreSQL
**å¼€å‘å‘¨æœŸ**: 5å¤©æ¸è¿›å¼å­¦ä¹ é¡¹ç›®

### ğŸ¯ é¡¹ç›®ç›®æ ‡

æ„å»ºä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„å¼‚æ­¥AIä»»åŠ¡å¤„ç†ç³»ç»Ÿï¼Œå®ç°ï¼š
- ğŸš€ **é«˜æ€§èƒ½**: APIå“åº”æ—¶é—´ <100ms
- ğŸ”„ **å¼‚æ­¥å¤„ç†**: åå°å¤„ç†AIè€—æ—¶ä»»åŠ¡
- ğŸ“Š **å®æ—¶ç›‘æ§**: å®Œæ•´çš„ä»»åŠ¡çŠ¶æ€è·Ÿè¸ª
- ğŸ›¡ï¸ **å¯é æ€§**: é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨é‡è¯•
- ğŸ”§ **å¯æ‰©å±•**: æ°´å¹³æ‰©å±•å’Œæ¨¡å—åŒ–è®¾è®¡

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    æ¶ˆæ¯     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Client    â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶   â”‚   FastAPI       â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â–¶   â”‚     Redis       â”‚
â”‚  (æµè§ˆå™¨/API)   â”‚           â”‚   åº”ç”¨æœåŠ¡å™¨     â”‚           â”‚   æ¶ˆæ¯é˜Ÿåˆ—       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                              â”‚                              â”‚
        â”‚                              â†“                              â†“
        â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚ PostgreSQL  â”‚                 â”‚   Celery     â”‚
        â”‚                        â”‚   æ•°æ®åº“     â”‚                 â”‚   Worker     â”‚
        â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                              â”‚                              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     ä»»åŠ¡çŠ¶æ€åŒæ­¥å’Œç»“æœå­˜å‚¨
```

### æ ¸å¿ƒç»„ä»¶è¯´æ˜

| ç»„ä»¶ | èŒè´£ | æŠ€æœ¯å®ç° |
|------|------|----------|
| **FastAPI** | æ¥æ”¶HTTPè¯·æ±‚ï¼Œç«‹å³å“åº”ï¼Œè§¦å‘å¼‚æ­¥ä»»åŠ¡ | `app/main.py`, `app/api/` |
| **Redis** | æ¶ˆæ¯é˜Ÿåˆ—ï¼Œå­˜å‚¨å¾…å¤„ç†ä»»åŠ¡å’Œç»“æœ | `redis:6379/1`(é˜Ÿåˆ—), `redis:6379/2`(ç»“æœ) |
| **Celery** | å¼‚æ­¥ä»»åŠ¡å¤„ç†ï¼ŒçŠ¶æ€ç®¡ç† | `app/worker/app.py`, `app/worker/tasks/` |
| **PostgreSQL** | æŒä¹…åŒ–å­˜å‚¨ä»»åŠ¡è®°å½•å’ŒçŠ¶æ€ | `app/models.py`, `app/database.py` |
| **Flower** | ä»»åŠ¡ç›‘æ§å’Œç®¡ç†é¢æ¿ | `celery flower --port=5555` |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.12+
- Docker & Docker Compose
- Redis Server
- PostgreSQL 16+
- 4GB+ RAM

### ä¸€é”®å¯åŠ¨

```bash
# 1. å…‹éš†é¡¹ç›®ï¼ˆå·²å…‹éš†å¯è·³è¿‡ï¼‰
git clone <repository-url>
cd async-ai-task-runner

# 2. å®‰è£…ä¾èµ–
source .venv/bin/activate
uv sync

# 3. å¯åŠ¨RedisæœåŠ¡
docker run -d --name redis-ai-task -p 6379:6379 redis:7-alpine

# 4. å¯åŠ¨PostgreSQLï¼ˆå¦‚æœæœªè¿è¡Œï¼‰
docker run -d --name async-ai-postgres -p 5433:5432 \
  -e POSTGRES_DB=task_runner \
  -e POSTGRES_USER=taskuser \
  -e POSTGRES_PASSWORD=taskpass \
  postgres:16

# 5. æ•°æ®åº“è¿ç§»
alembic upgrade head

# 6. å¯åŠ¨Celery Worker
celery -A app.worker worker --loglevel=info --concurrency=2

# 7. å¯åŠ¨FastAPIæœåŠ¡
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 8. å¯åŠ¨ç›‘æ§é¢æ¿ï¼ˆå¯é€‰ï¼‰
celery -A app.worker flower --port=5555
```

### éªŒè¯å®‰è£…

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
source .venv/bin/activate
python quick_test.py

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8000/api/v1/health
```

**é¢„æœŸè¾“å‡º**:
```
ğŸ§ª Async AI Task Runner å¿«é€Ÿæµ‹è¯•
==================================================
ğŸ”§ ç›´æ¥æµ‹è¯• Celery ä»»åŠ¡
âœ… è®¡ç®—ä»»åŠ¡æˆåŠŸ: 10 + 20 = 30
ğŸš€ æµ‹è¯• FastAPI + Celery åŸºæœ¬å·¥ä½œæµç¨‹
âœ… FastAPI æœåŠ¡æ­£å¸¸: {'status': 'healthy'}
âœ… ä»»åŠ¡æäº¤æˆåŠŸ: ID=X, çŠ¶æ€=PENDING
âœ… ä»»åŠ¡å®Œæˆ! ç»“æœé•¿åº¦: 67å­—ç¬¦
ğŸ“Š æµ‹è¯•ç»“æœ:
  Celery ä»»åŠ¡: âœ… é€šè¿‡
  API é›†æˆ: âœ… é€šè¿‡
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! ç³»ç»Ÿè¿è¡Œæ­£å¸¸
```

---

## ğŸ“ é¡¹ç›®ç»“æ„è¯¦è§£

```
async-ai-task-runner/
â”œâ”€â”€ ğŸ“ app/                          # ä¸»åº”ç”¨åŒ…
â”‚   â”œâ”€â”€ ğŸ“ api/                      # APIè·¯ç”±å±‚
â”‚   â”‚   â”œâ”€â”€ ğŸ“ v1/                   # APIç‰ˆæœ¬1
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ endpoints/       # ç«¯ç‚¹å®ç°
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ health.py        # å¥åº·æ£€æŸ¥ç«¯ç‚¹
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tasks.py         # ä»»åŠ¡ç®¡ç†ç«¯ç‚¹ â­
â”‚   â”‚   â”‚   â””â”€â”€ api.py              # APIè·¯ç”±èšåˆ
â”‚   â”‚   â””â”€â”€ ğŸ“ deps/                 # ä¾èµ–æ³¨å…¥
â”‚   â”‚       â””â”€â”€ common.py            # é€šç”¨ä¾èµ–
â”‚   â”œâ”€â”€ ğŸ“ core/                     # æ ¸å¿ƒé…ç½®
â”‚   â”‚   â””â”€â”€ config.py                # åº”ç”¨é…ç½® â­
â”‚   â”œâ”€â”€ ğŸ“ crud/                     # æ•°æ®è®¿é—®å±‚
â”‚   â”‚   â””â”€â”€ task.py                  # ä»»åŠ¡CRUDæ“ä½œ â­
â”‚   â”œâ”€â”€ ğŸ“ models/                   # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ .py                      # SQLAlchemyæ¨¡å‹
â”‚   â”œâ”€â”€ ğŸ“ schemas/                  # Pydanticæ¨¡å¼
â”‚   â”‚   â””â”€â”€ .py                      # è¯·æ±‚/å“åº”æ¨¡å¼
â”‚   â”œâ”€â”€ ğŸ“ worker/                   # Celeryå·¥ä½œè¿›ç¨‹
â”‚   â”‚   â”œâ”€â”€ app.py                    # Celeryåº”ç”¨é…ç½® â­
â”‚   â”‚   â””â”€â”€ ğŸ“ tasks/                 # ä»»åŠ¡å®šä¹‰
â”‚   â”‚       â”œâ”€â”€ ai_tasks.py           # AIå¤„ç†ä»»åŠ¡ â­
â”‚   â”‚       â””â”€â”€ demo_tasks.py         # æ¼”ç¤ºä»»åŠ¡
â”‚   â”œâ”€â”€ database.py                   # æ•°æ®åº“é…ç½® â­
â”‚   â””â”€â”€ main.py                       # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ ğŸ“ alembic/                       # æ•°æ®åº“è¿ç§»
â”œâ”€â”€ ğŸ“ demos/                         # æ¼”ç¤ºå’Œå­¦ä¹ ä»£ç 
â”‚   â”œâ”€â”€ ğŸ“ tests/                     # æµ‹è¯•æ–‡ä»¶
â”‚   â””â”€â”€ *.py                         # æ¼”ç¤ºè„šæœ¬
â”œâ”€â”€ pyproject.toml                    # é¡¹ç›®é…ç½®å’Œä¾èµ– â­
â”œâ”€â”€ alembic.ini                      # Alembicé…ç½®
â”œâ”€â”€ quick_test.py                     # å¿«é€ŸåŠŸèƒ½æµ‹è¯• â­
â””â”€â”€ docs/                            # æ–‡æ¡£ç›®å½•
```

**å…³é”®æ–‡ä»¶è¯´æ˜** (â­ æ ‡è®°)ï¼š
- [`app/core/config.py`](app/core/config.py) - åº”ç”¨é…ç½®å’Œç¯å¢ƒå˜é‡
- [`app/database.py`](app/database.py) - åŒæ•°æ®åº“å¼•æ“é…ç½®ï¼ˆå¼‚æ­¥+åŒæ­¥ï¼‰
- [`app/models.py`](app/models.py) - SQLAlchemyæ•°æ®æ¨¡å‹
- [`app/worker/app.py`](app/worker/app.py) - Celeryåº”ç”¨é…ç½®
- [`app/worker/tasks/ai_tasks.py`](app/worker/tasks/ai_tasks.py) - AIä»»åŠ¡å®ç°
- [`app/crud/task.py`](app/crud/task.py) - æ•°æ®åº“æ“ä½œï¼ˆå¼‚æ­¥+åŒæ­¥ç‰ˆæœ¬ï¼‰
- [`app/api/v1/endpoints/tasks.py`](app/api/v1/endpoints/tasks.py) - FastAPIé›†æˆç‚¹
- [`pyproject.toml`](pyproject.toml) - é¡¹ç›®ä¾èµ–å’Œé…ç½®
- [`quick_test.py`](quick_test.py) - åŠŸèƒ½éªŒè¯è„šæœ¬

---

## ğŸ”§ é…ç½®è¯¦è§£

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæœ¬åœ°å¼€å‘ï¼‰ï¼š
```bash
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://taskuser:taskpass@localhost:5433/task_runner

# Redis & Celery é…ç½®
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# åº”ç”¨é…ç½®
DEBUG=true
API_V1_STR=/api/v1
```

### Celery é«˜çº§é…ç½®

**æ–‡ä»¶**: [`app/worker/app.py`](app/worker/app.py:24-40)

```python
celery_app.conf.update(
    # åºåˆ—åŒ–é…ç½®
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,

    # ä»»åŠ¡è·¯ç”±é…ç½®
    task_routes={
        "app.worker.tasks.ai_tasks.*": {"queue": "ai_processing"},
        "app.worker.tasks.demo_tasks.*": {"queue": "demo_tasks"},
    },

    # æ€§èƒ½é…ç½®
    worker_prefetch_multiplier=1,
    task_acks_late=True,

    # ç»“æœå’Œç›‘æ§é…ç½®
    result_expires=3600,
    worker_send_task_events=True,
    task_send_sent_event=True,

    # å¯é æ€§é…ç½®
    worker_disable_rate_limits=False,
    task_reject_on_worker_lost=True,
)
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. å¼‚æ­¥ä»»åŠ¡å¤„ç†æµç¨‹

```python
# app/api/v1/endpoints/tasks.py
@router.post("/tasks")
async def create_task(task_in: TaskCreate, db: AsyncSession = Depends(get_db)):
    """
    å¼‚æ­¥ä»»åŠ¡åˆ›å»ºæµç¨‹ï¼š
    1. åˆ›å»ºæ•°æ®åº“è®°å½• (ç«‹å³)
    2. è§¦å‘Celeryä»»åŠ¡ (å¼‚æ­¥)
    3. ç«‹å³è¿”å›å“åº” (å¿«é€Ÿ)
    """
    # æ­¥éª¤1: åˆ›å»ºæ•°æ®åº“è®°å½•
    task = await task_crud.create_task(db=db, obj_in=task_in)

    # æ­¥éª¤2: è§¦å‘å¼‚æ­¥ä»»åŠ¡
    try:
        run_ai_text_generation.delay(
            task_id=str(task.id),
            prompt=task.prompt,
            model=task.model or "gpt-3.5-turbo"
        )
    except Exception as celery_error:
        # å®¹é”™å¤„ç† - Celeryå¤±è´¥ä¸å½±å“APIå“åº”
        print(f"âš ï¸ Failed to trigger Celery task: {celery_error}")

    # æ­¥éª¤3: ç«‹å³è¿”å›
    return task
```

### 2. AIä»»åŠ¡å®ç°

**æ–‡ä»¶**: [`app/worker/tasks/ai_tasks.py`](app/worker/tasks/ai_tasks.py)

```python
@celery_app.task(bind=True, name="run_ai_text_generation")
def run_ai_text_generation(self, task_id: str, prompt: str, model: str):
    """
    AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ç‰¹æ€§ï¼š
    1. è¿›åº¦è·Ÿè¸ª (bind=True)
    2. æ•°æ®åº“çŠ¶æ€åŒæ­¥
    3. é”™è¯¯é‡è¯•æœºåˆ¶
    4. æ™ºèƒ½ç»“æœç”Ÿæˆ
    """
    try:
        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        update_task_status(task_id, TaskStatus.PROCESSING)

        # æ¨¡æ‹ŸAIå¤„ç†æ—¶é—´ï¼ˆ5-15ç§’ï¼‰
        processing_time = random.uniform(5, 15)

        # è¿›åº¦è·Ÿè¸ª
        for i in range(int(processing_time)):
            time.sleep(1)
            progress = int((i + 1) / processing_time * 100)

            self.update_state(
                state='PROGRESS',
                meta={
                    'progress': progress,
                    'status': f'å¤„ç†ä¸­... {progress}%'
                }
            )

        # ç”ŸæˆAIç»“æœ
        result = generate_ai_response(prompt)

        # æ›´æ–°æœ€ç»ˆçŠ¶æ€å’Œç»“æœ
        update_task_result(task_id, TaskStatus.COMPLETED, result)

        return {
            'task_id': task_id,
            'status': 'completed',
            'result': result,
            'processing_time': processing_time
        }

    except Exception as e:
        # é”™è¯¯å¤„ç†å’Œé‡è¯•
        update_task_result(task_id, TaskStatus.FAILED, str(e))
        raise self.retry(exc=e, countdown=60, max_retries=3)
```

### 3. æ•°æ®åº“åŒå¼•æ“è®¾è®¡

**æ–‡ä»¶**: [`app/database.py`](app/database.py:31-57)

```python
# å¼‚æ­¥å¼•æ“ (FastAPIä½¿ç”¨)
engine = create_async_engine(settings.database_url)
AsyncSessionLocal = sessionmaker(engine, class_=AsyncSession)

# åŒæ­¥å¼•æ“ (Celeryä½¿ç”¨)
sync_database_url = settings.database_url.replace("postgresql+asyncpg://", "postgresql://")
sync_engine = create_engine(sync_database_url)
SyncSessionLocal = sessionmaker(sync_engine, autocommit=False, autoflush=False)

@contextlib.contextmanager
def get_sync_db_session():
    """åŒæ­¥æ•°æ®åº“ä¼šè¯ - ä¾›Celeryä»»åŠ¡ä½¿ç”¨"""
    session = SyncSessionLocal()
    try:
        yield session
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()
```

---

## ğŸ“Š ç›‘æ§å’Œè¿ç»´

### ç›‘æ§å·¥å…·

#### 1. Flower ç›‘æ§é¢æ¿

```bash
# å¯åŠ¨Flower
celery -A app.worker flower --port=5555

# è®¿é—®åœ°å€
http://localhost:5555
```

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- ğŸ“Š å®æ—¶ä»»åŠ¡ç»Ÿè®¡
- ğŸ‘¥ WorkerçŠ¶æ€ç›‘æ§
- ğŸ“ˆ ä»»åŠ¡æ‰§è¡Œå†å²
- ğŸ”§ ä»»åŠ¡ç®¡ç†ï¼ˆé‡è¯•ã€æ’¤é”€ï¼‰

#### 2. å¥åº·æ£€æŸ¥

```bash
# APIå¥åº·æ£€æŸ¥
curl http://localhost:8000/api/v1/health

# å“åº”ç¤ºä¾‹
{
    "status": "healthy",
    "app_name": "Async AI Task Runner",
    "version": "0.1.0",
    "timestamp": "2025-11-26T10:55:40.865467Z"
}
```

#### 3. æ—¥å¿—ç›‘æ§

**Workeræ—¥å¿—**:
```bash
[INFO] Task run_ai_text_generation[abc123] received
[INFO] ğŸ¤– å¼€å§‹å¤„ç†AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡: 16
[INFO] ğŸ“ Prompt: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ
[INFO] â³ é¢„è®¡å¤„ç†æ—¶é—´: 13.0ç§’
[INFO] âœ… AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡å®Œæˆ: 16
[INFO] Task run_ai_text_generation[abc123] succeeded in 13.2s
```

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **APIå“åº”æ—¶é—´** | <100ms | ç«‹å³è¿”å›Task ID |
| **ä»»åŠ¡å¤„ç†æ—¶é—´** | 5-15ç§’ | AIä»»åŠ¡å¤„ç†æ—¶é—´ |
| **å¹¶å‘Workeræ•°** | 2ä¸ª | å¯é…ç½® |
| **ä»»åŠ¡é˜Ÿåˆ—å®¹é‡** | æ— é™åˆ¶ | Rediså†…å­˜é™åˆ¶ |
| **ç»“æœè¿‡æœŸæ—¶é—´** | 1å°æ—¶ | å¯é…ç½® |

---

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### 1. å®Œæ•´åŠŸèƒ½æµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´é›†æˆæµ‹è¯•
source .venv/bin/activate
python test_complete_integration.py

# å¿«é€ŸåŠŸèƒ½æµ‹è¯•
python quick_test.py
```

### 2. æ‰‹åŠ¨æµ‹è¯•æ­¥éª¤

#### æ­¥éª¤1: æäº¤AIä»»åŠ¡

```bash
curl -X POST http://localhost:8000/api/v1/tasks \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—",
    "model": "gpt-3.5-turbo",
    "priority": 5
  }'
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "id": 123,
  "prompt": "è§£é‡Šä»€ä¹ˆæ˜¯é‡å­è®¡ç®—",
  "model": "gpt-3.5-turbo",
  "priority": 5,
  "status": "PENDING",
  "result": null,
  "created_at": "2025-11-26T10:55:40.865467Z",
  "updated_at": null
}
```

#### æ­¥éª¤2: æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

```bash
curl http://localhost:8000/api/v1/tasks/123
```

**çŠ¶æ€æ¼”è¿›**:
```json
// 1. åˆå§‹çŠ¶æ€
{"status": "PENDING"}

// 2. å¤„ç†ä¸­
{"status": "PROCESSING"}

// 3. å®Œæˆ
{
  "status": "COMPLETED",
  "result": "é‡å­è®¡ç®—æ˜¯ä¸€ç§åˆ©ç”¨é‡å­åŠ›å­¦åŸç†è¿›è¡Œä¿¡æ¯å¤„ç†çš„æ–°å‹è®¡ç®—æ¨¡å¼..."
}
```

### 3. æ€§èƒ½æµ‹è¯•

```bash
# å¹¶å‘æµ‹è¯•
python -c "
import requests
import time
import concurrent.futures

def submit_task(prompt):
    response = requests.post('http://localhost:8000/api/v1/tasks', json={
        'prompt': prompt,
        'model': 'gpt-3.5-turbo'
    })
    return response.json()['id']

# å¹¶å‘æäº¤10ä¸ªä»»åŠ¡
with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
    prompts = [f'æµ‹è¯•é—®é¢˜{i}' for i in range(10)]
    task_ids = list(executor.map(submit_task, prompts))

print(f'æäº¤äº† {len(task_ids)} ä¸ªä»»åŠ¡')
print(f'ä»»åŠ¡ID: {task_ids}')
"
```

---

## ğŸ› ï¸ å¼€å‘å’Œæ‰©å±•

### æ·»åŠ æ–°ä»»åŠ¡ç±»å‹

#### 1. åˆ›å»ºä»»åŠ¡æ–‡ä»¶

```python
# app/worker/tasks/email_tasks.py
from app.worker.app import celery_app

@celery_app.task(bind=True, max_retries=3)
def send_email_task(self, recipient, subject, content):
    """
    é‚®ä»¶å‘é€ä»»åŠ¡
    """
    try:
        # é‚®ä»¶å‘é€é€»è¾‘
        result = send_email(recipient, subject, content)

        # æ›´æ–°æ•°æ®åº“çŠ¶æ€
        update_task_status(task_id, TaskStatus.COMPLETED)

        return {
            'recipient': recipient,
            'subject': subject,
            'sent_at': time.time()
        }

    except Exception as exc:
        # é‡è¯•æœºåˆ¶
        raise self.retry(exc=exc, countdown=60)
```

#### 2. æ³¨å†Œä»»åŠ¡æ¨¡å—

**æ–‡ä»¶**: [`app/worker/app.py`](app/worker/app.py:18-20)

```python
include=[
    "app.worker.tasks.ai_tasks",
    "app.worker.tasks.demo_tasks",
    "app.worker.tasks.email_tasks",  # æ–°å¢
]
```

#### 3. é…ç½®ä»»åŠ¡è·¯ç”±

```python
celery_app.conf.update(
    task_routes={
        "app.worker.tasks.ai_tasks.*": {"queue": "ai_processing"},
        "app.worker.tasks.demo_tasks.*": {"queue": "demo_tasks"},
        "app.worker.tasks.email_tasks.*": {"queue": "email_tasks"},  # æ–°å¢
    },
)
```

### æ·»åŠ å®šæ—¶ä»»åŠ¡

```python
# app/worker/tasks/scheduled_tasks.py
from celery.schedules import crontab

# å®šæ—¶æ¸…ç†ä»»åŠ¡
@celery_app.task
def cleanup_old_tasks():
    """æ¸…ç†7å¤©å‰çš„ä»»åŠ¡è®°å½•"""
    # å®ç°æ¸…ç†é€»è¾‘
    return f"Cleaned up {count} old tasks"

# é…ç½®å®šæ—¶ä»»åŠ¡
celery_app.conf.beat_schedule = {
    'daily-cleanup': {
        'task': 'app.worker.tasks.scheduled_tasks.cleanup_old_tasks',
        'schedule': crontab(hour=2, minute=0),  # æ¯å¤©å‡Œæ™¨2ç‚¹
    },
}
```

**å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨**:
```bash
celery -A app.worker beat --loglevel=info
```

---

## ğŸš€ ç”Ÿäº§éƒ¨ç½²

### Docker éƒ¨ç½²é…ç½®

#### 1. åˆ›å»º Dockerfile

```dockerfile
# Dockerfile
FROM python:3.12-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pyproject.toml uv.lock ./

# å®‰è£…Pythonä¾èµ–
RUN pip install uv
RUN pip install -e .

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 2. Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # RedisæœåŠ¡
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # PostgreSQLæœåŠ¡
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: task_runner
      POSTGRES_USER: taskuser
      POSTGRES_PASSWORD: taskpass
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # FastAPIåº”ç”¨
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://taskuser:taskpass@postgres:5432/task_runner
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
    depends_on:
      - postgres
      - redis
    volumes:
      - ./app:/app/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000

  # Celery Worker
  worker:
    build: .
    environment:
      - DATABASE_URL=postgresql+asyncpg://taskuser:taskpass@postgres:5432/task_runner
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
    depends_on:
      - postgres
      - redis
    volumes:
      - ./app:/app/app
    command: celery -A app.worker worker --loglevel=info --concurrency=4

  # Celery Beat (å®šæ—¶ä»»åŠ¡)
  beat:
    build: .
    environment:
      - DATABASE_URL=postgresql+asyncpg://taskuser:taskpass@postgres:5432/task_runner
      - CELERY_BROKER_URL=redis://redis:6379/1
    depends_on:
      - redis
    volumes:
      - ./app:/app/app
    command: celery -A app.worker beat --loglevel=info

  # Flowerç›‘æ§
  flower:
    build: .
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
    ports:
      - "5555:5555"
    depends_on:
      - redis
    command: celery -A app.worker flower --port=5555

volumes:
  postgres_data:
  redis_data:
```

#### 3. å¯åŠ¨ç”Ÿäº§ç¯å¢ƒ

```bash
# æ„å»ºå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up --build -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f web
docker-compose logs -f worker
docker-compose logs -f flower

# åœæ­¢æœåŠ¡
docker-compose down

# æ‰©å±•Workeræ•°é‡
docker-compose up --scale worker=4
```

### ç¯å¢ƒå˜é‡é…ç½®

**ç”Ÿäº§ç¯å¢ƒ `.env` æ–‡ä»¶**:
```bash
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql+asyncpg://taskuser:taskpass@postgres:5432/task_runner

# Redisé…ç½®
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2

# åº”ç”¨é…ç½®
DEBUG=false
API_V1_STR=/api/v1

# å®‰å…¨é…ç½®
SECRET_KEY=your-secret-key-here
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 1. Workeré…ç½®ä¼˜åŒ–

```bash
# ç”Ÿäº§ç¯å¢ƒWorkeré…ç½®
celery -A app.worker worker \
    --loglevel=info \
    --concurrency=4 \
    --prefetch-multiplier=1 \
    --max-tasks-per-child=1000 \
    --time-limit=300 \
    --soft-time-limit=240
```

### 2. Redisé…ç½®ä¼˜åŒ–

```python
# é«˜çº§Redisé…ç½®
celery_app.conf.update(
    broker_pool_limit=10,              # è¿æ¥æ± å¤§å°
    broker_connection_timeout=30,      # è¿æ¥è¶…æ—¶
    broker_transport_options={
        'visibility_timeout': 3600,     # ä»»åŠ¡å¯è§æ€§è¶…æ—¶
        'retry_policy': {
            'timeout': 5.0
        }
    }
)
```

### 3. æ•°æ®åº“ä¼˜åŒ–

```python
# æ•°æ®åº“è¿æ¥æ± é…ç½®
engine = create_async_engine(
    settings.database_url,
    echo=settings.debug,
    pool_size=20,                    # è¿æ¥æ± å¤§å°
    max_overflow=30,                 # æœ€å¤§æº¢å‡ºè¿æ¥
    pool_pre_ping=True,               # è¿æ¥å‰ping
    pool_recycle=3600,               # è¿æ¥å›æ”¶æ—¶é—´
)
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. ä»»åŠ¡ä¸æ‰§è¡Œ

**é—®é¢˜**: ä»»åŠ¡æäº¤åçŠ¶æ€ä¸€ç›´æ˜¯PENDING

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥WorkerçŠ¶æ€
celery -A app.worker inspect active

# 2. æ£€æŸ¥ä»»åŠ¡æ³¨å†Œ
celery -A app.worker inspect registered | grep your_task_name

# 3. æŸ¥çœ‹é˜Ÿåˆ—é•¿åº¦
docker exec redis-ai-task redis-cli llen celery

# 4. æ£€æŸ¥Workeræ—¥å¿—
docker-compose logs worker
```

#### 2. æ•°æ®åº“è¿æ¥é”™è¯¯

**é—®é¢˜**: Celeryä»»åŠ¡ä¸­æ•°æ®åº“è¿æ¥å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… æ­£ç¡®çš„æ•°æ®åº“ä½¿ç”¨æ–¹å¼
from app.database import get_sync_db_session

@celery_app.task
def db_task():
    with get_sync_db_session() as db:
        return db.query(Task).all()

# âŒ é”™è¯¯çš„æ–¹å¼
@celery_app.task
async def bad_db_task():
    async with get_db() as db:  # ä¸èƒ½åœ¨Celeryä¸­ä½¿ç”¨async
        return await db.query(Task).all()
```

#### 3. å†…å­˜æ³„æ¼

**é—®é¢˜**: Workerå†…å­˜æŒç»­å¢é•¿

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é™åˆ¶æ¯ä¸ªWorkerå¤„ç†çš„ä»»åŠ¡æ•°
celery -A app.worker worker --max-tasks-per-child=1000

# å®šæœŸé‡å¯Worker
# ä½¿ç”¨supervisorç­‰è¿›ç¨‹ç®¡ç†å·¥å…·
```

#### 4. ä»»åŠ¡é‡å¤æ‰§è¡Œ

**é—®é¢˜**: ç›¸åŒä»»åŠ¡è¢«æ‰§è¡Œå¤šæ¬¡

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿ä»»åŠ¡å¹‚ç­‰æ€§
@celery_app.task
def idempotent_task(unique_id):
    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if is_processed(unique_id):
        return get_result(unique_id)

    # å¤„ç†ä»»åŠ¡
    result = process_task(unique_id)

    # æ ‡è®°å·²å¤„ç†
    mark_processed(unique_id, result)

    return result
```

---

## ğŸ“š æ‰©å±•é˜…è¯»

### é¡¹ç›®æ–‡æ¡£

1. **[CELERY_BEGINNER_TUTORIAL.md](CELERY_BEGINNER_TUTORIAL.md)** - å®Œæ•´çš„Celeryæ–°æ‰‹æ•™ç¨‹
2. **[CELERY_QUICK_REFERENCE.md](CELERY_QUICK_REFERENCE.md)** - å¿«é€Ÿå‚è€ƒæ‰‹å†Œ
3. **[PROJECT_CELERY_ANALYSIS.md](PROJECT_CELERY_ANALYSIS.md)** - é¡¹ç›®å®ç°æ·±åº¦åˆ†æ
4. **[DAY2_MORNING_DEVELOPMENT_DOCUMENTATION.md](DAY2_MORNING_DEVELOPMENT_DOCUMENTATION.md)** - Day2å¼€å‘æ–‡æ¡£
5. **[DAY2_ARCHITECTURE_DIAGRAM.md](DAY2_ARCHITECTURE_DIAGRAM.md)** - æ¶æ„å›¾å’ŒæŠ€æœ¯åˆ†æ

### å¤–éƒ¨èµ„æº

- [Celery å®˜æ–¹æ–‡æ¡£](https://docs.celeryproject.org/)
- [FastAPI å®˜æ–¹æ–‡æ¡£](https://fastapi.tiangolo.com/)
- [Redis å®˜æ–¹æ–‡æ¡£](https://redis.io/documentation/)
- [Flower ç›‘æ§æ–‡æ¡£](https://flower.readthedocs.io/)
- [Pydantic æ–‡æ¡£](https://pydantic-docs.helpmanual.io/)

---

## ğŸ‰ æ€»ç»“

### é¡¹ç›®æˆå°±

âœ… **å®Œæ•´å®ç°**: ä»æ¦‚å¿µåˆ°ç”Ÿäº§çš„å®Œæ•´å¼‚æ­¥ä»»åŠ¡å¤„ç†ç³»ç»Ÿ
âœ… **é«˜æ€§èƒ½**: APIå“åº”æ—¶é—´ä»ç§’çº§é™ä½åˆ°æ¯«ç§’çº§
âœ… **å¯é æ€§**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
âœ… **å¯æ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ°´å¹³æ‰©å±•
âœ… **å¯è§‚æµ‹**: å®Œæ•´çš„ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ
âœ… **ç”Ÿäº§å°±ç»ª**: åŒ…å«Dockeréƒ¨ç½²å’Œè¿ç»´é…ç½®

### æŠ€æœ¯äº®ç‚¹

- ğŸ”„ **å¼‚æ­¥æ¶æ„**: FastAPI + Celery + Redisçš„å®Œç¾ç»“åˆ
- ğŸ¯ **åŒæ•°æ®åº“å¼•æ“**: å¼‚æ­¥+åŒæ­¥ï¼Œæ»¡è¶³ä¸åŒéœ€æ±‚
- ğŸ“Š **å®æ—¶ç›‘æ§**: Floweré¢æ¿ + è¯¦ç»†æ—¥å¿—
- ğŸ›¡ï¸ **å®¹é”™è®¾è®¡**: å¤šå±‚é”™è¯¯å¤„ç†å’Œè‡ªåŠ¨é‡è¯•
- ğŸ”§ **æ¨¡å—åŒ–**: æ¸…æ™°çš„ä»£ç ç»„ç»‡å’ŒèŒè´£åˆ†ç¦»

### å­¦ä¹ ä»·å€¼

è¿™ä¸ªé¡¹ç›®å®Œç¾å±•ç¤ºäº†ç°ä»£Python Webå¼€å‘çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬ï¼š
- å¼‚æ­¥ç¼–ç¨‹æ¦‚å¿µå’Œå®ç°
- åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡
- å¾®æœåŠ¡æ¶æ„æ¨¡å¼
- å®¹å™¨åŒ–éƒ¨ç½²
- ç›‘æ§å’Œè¿ç»´

**è¿™å·²ç»æ˜¯ä¸€ä¸ªå¯ä»¥ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒçš„å®Œæ•´å¼‚æ­¥ä»»åŠ¡å¤„ç†å¹³å°ï¼** ğŸš€