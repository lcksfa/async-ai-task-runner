# Celery å¿«é€Ÿå‚è€ƒæ‰‹å†Œ

## ğŸš€ å¿«é€Ÿå¯åŠ¨å‘½ä»¤

```bash
# 1. å¯åŠ¨ Redis
docker run -d --name redis-ai-task -p 6379:6379 redis:7-alpine

# 2. å¯åŠ¨ Celery Worker
source .venv/bin/activate
celery -A app.worker worker --loglevel=info --concurrency=2

# 3. å¯åŠ¨ Flower ç›‘æ§ï¼ˆå¯é€‰ï¼‰
celery -A app.worker flower --port=5555

# 4. å¯åŠ¨ FastAPIï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰
source .venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“‹ å¸¸ç”¨å‘½ä»¤

### Worker ç®¡ç†
```bash
# æŸ¥çœ‹æ´»åŠ¨ä»»åŠ¡
celery -A app.worker inspect active

# æŸ¥çœ‹æ³¨å†Œçš„ä»»åŠ¡
celery -A app.worker inspect registered

# æŸ¥çœ‹Workerç»Ÿè®¡
celery -A app.worker inspect stats

# é‡å¯Worker
celery -A app.worker control pool_restart
```

### ä»»åŠ¡ç®¡ç†
```bash
# æ’¤é”€ä»»åŠ¡
celery -A app.worker control revoke <task_id> --terminate

# æ¸…ç©ºé˜Ÿåˆ—
celery -A app.worker control purge

# æŸ¥çœ‹é˜Ÿåˆ—é•¿åº¦
docker exec redis-ai-task redis-cli llen celery
```

## ğŸ§ª æµ‹è¯•å‘½ä»¤

```bash
# è¿è¡Œå¿«é€Ÿæµ‹è¯•
source .venv/bin/activate
python quick_test.py

# æµ‹è¯•ç‰¹å®šä»»åŠ¡
python -c "
from app.worker.tasks.demo_tasks import simple_calculation
result = simple_calculation.delay(10, 20, 'add')
print(f'ä»»åŠ¡ID: {result.id}')
print(f'ç»“æœ: {result.get(timeout=10)}')
"
```

## ğŸ”§ ä»£ç æ¨¡æ¿

### 1. åˆ›å»ºæ–°ä»»åŠ¡

```python
# app/worker/tasks/your_tasks.py
from app.worker.app import celery_app

@celery_app.task(name="your_task_name")
def your_task(param1, param2):
    """ä»»åŠ¡æè¿°"""
    try:
        # ä»»åŠ¡é€»è¾‘
        result = do_something(param1, param2)
        return {"status": "success", "result": result}
    except Exception as e:
        # é”™è¯¯å¤„ç†
        raise

# å¸¦é‡è¯•çš„ä»»åŠ¡
@celery_app.task(bind=True, max_retries=3)
def retry_task(self, data):
    try:
        return process_data(data)
    except Exception as exc:
        raise self.retry(exc=exc, countdown=60)
```

### 2. åœ¨FastAPIä¸­è°ƒç”¨ä»»åŠ¡

```python
# app/api/v1/endpoints/your_endpoint.py
from app.worker.tasks.your_tasks import your_task

@router.post("/process")
async def process_data(data: YourSchema):
    # åˆ›å»ºæ•°æ®åº“è®°å½•
    db_record = await create_record(data)

    # è§¦å‘å¼‚æ­¥ä»»åŠ¡
    your_task.delay(
        record_id=str(db_record.id),
        data=data.dict()
    )

    return {"task_id": db_record.id, "status": "PENDING"}
```

### 3. ä»»åŠ¡çŠ¶æ€æ›´æ–°

```python
# app/crud/task.py ä¸­çš„ç¤ºä¾‹
def update_task_status(task_id, status):
    """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
    from app.database import get_sync_db_session
    with get_sync_db_session() as db:
        task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            task.status = status
            db.commit()
            return True
    return False
```

## ğŸ“Š ç›‘æ§åœ°å€

- **Flower ç›‘æ§**: http://localhost:5555
- **FastAPI æ–‡æ¡£**: http://localhost:8000/docs
- **å¥åº·æ£€æŸ¥**: http://localhost:8000/api/v1/health

## ğŸ› å¸¸è§é—®é¢˜è§£å†³

### ä»»åŠ¡ä¸æ‰§è¡Œ
```bash
# 1. æ£€æŸ¥WorkerçŠ¶æ€
celery -A app.worker inspect active

# 2. æ£€æŸ¥ä»»åŠ¡æ³¨å†Œ
celery -A app.worker inspect registered | grep your_task_name

# 3. æŸ¥çœ‹Redisé˜Ÿåˆ—
docker exec redis-ai-task redis-cli llen celery
```

### æ•°æ®åº“è¿æ¥é—®é¢˜
```python
# âœ… æ­£ç¡®çš„æ•°æ®åº“ä½¿ç”¨æ–¹å¼
from app.database import get_sync_db_session

@celery_app.task
def db_task():
    with get_sync_db_session() as db:
        return db.query(Task).all()

# âŒ é”™è¯¯çš„æ–¹å¼ï¼ˆä¸èƒ½åœ¨Celeryä¸­ä½¿ç”¨asyncï¼‰
@celery_app.task
async def bad_db_task():
    async with get_db() as db:
        return await db.query(Task).all()
```

### Worker æ— å“åº”
```bash
# é‡å¯Worker
pkill -f "celery.*worker"
celery -A app.worker worker --loglevel=info --concurrency=2
```

## ğŸ”§ é…ç½®å‚è€ƒ

### app/core/config.py
```python
class Settings(BaseSettings):
    # Celery é…ç½®
    celery_broker_url: str = "redis://localhost:6379/1"
    celery_result_backend: str = "redis://localhost:6379/2"
```

### app/worker/app.py
```python
celery_app.conf.update(
    # ä»»åŠ¡è·¯ç”±
    task_routes={
        "app.worker.tasks.ai_tasks.*": {"queue": "ai_processing"},
        "app.worker.tasks.urgent.*": {"queue": "urgent"},
    },

    # æ€§èƒ½é…ç½®
    worker_prefetch_multiplier=1,
    task_acks_late=True,

    # é‡è¯•é…ç½®
    task_soft_time_limit=300,
    task_time_limit=360,
)
```

## ğŸ“ æ—¥å¿—ç¤ºä¾‹

### æˆåŠŸçš„Workerå¯åŠ¨
```
ğŸš€ Celeryåº”ç”¨å·²åˆå§‹åŒ–
ğŸ“¡ Broker: redis://localhost:6379/1
ğŸ’¾ Backend: redis://localhost:6379/2

 -------------- celery@hostname v5.5.3
--- ***** -----
-- ******* ----
- ** ----------
- ** ----------
- ** ----------
-- ******* ----
--- ***** -----
 -------------- [queues]
                .> celery           exchange=celery(direct) key=celery
```

### ä»»åŠ¡æ‰§è¡Œæ—¥å¿—
```
[INFO] Task your_task[abc123] received
[INFO] Task your_task[abc123] succeeded in 2.5s: {'result': 'success'}
```

### é”™è¯¯æ—¥å¿—
```
[ERROR] Task your_task[def456] raised exception: ValueError('Invalid data')
[ERROR] Traceback (most recent call last):
  File "/app/worker/tasks/your_tasks.py", line 10, in your_task
    raise ValueError('Invalid data')
```

## ğŸ¯ æœ€ä½³å®è·µæ£€æŸ¥æ¸…å•

- [ ] ä»»åŠ¡æ˜¯å¹‚ç­‰çš„ï¼ˆé‡å¤æ‰§è¡Œä¸ä¼šäº§ç”Ÿå‰¯ä½œç”¨ï¼‰
- [ ] æœ‰é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- [ ] ä½¿ç”¨åŒæ­¥æ•°æ®åº“ä¼šè¯ï¼ˆä¸ç”¨asyncï¼‰
- [ ] ä»»åŠ¡æœ‰æ˜ç¡®çš„åç§°ï¼ˆ@task(name="task_name")ï¼‰
- [ ] è®¾ç½®äº†åˆç†çš„è¶…æ—¶æ—¶é—´
- [ ] æ—¥å¿—è®°å½•å……åˆ†
- [ ] é¿å…åœ¨ä»»åŠ¡ä¸­å¤„ç†å¤§é‡æ•°æ®
- [ ] ä½¿ç”¨ä»»åŠ¡è·¯ç”±è¿›è¡Œè´Ÿè½½å‡è¡¡

## ğŸ“š æ›´å¤šèµ„æº

- [Celery å®˜æ–¹æ–‡æ¡£](https://docs.celeryproject.org/)
- [Flower ç›‘æ§æ–‡æ¡£](https://flower.readthedocs.io/)
- [Redis æ–‡æ¡£](https://redis.io/documentation)
- [é¡¹ç›®å®Œæ•´ç¤ºä¾‹](./CELERY_BEGINNER_TUTORIAL.md)