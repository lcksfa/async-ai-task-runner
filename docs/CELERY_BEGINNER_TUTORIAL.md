# Celery æ–°æ‰‹å®Œæ•´æ•™ç¨‹

## ğŸ“š ç›®å½•

1. [Celery ç®€ä»‹](#1-celery-ç®€ä»‹)
2. [æ ¸å¿ƒæ¦‚å¿µ](#2-æ ¸å¿ƒæ¦‚å¿µ)
3. [ç¯å¢ƒæ­å»º](#3-ç¯å¢ƒæ­å»º)
4. [åŸºç¡€é…ç½®](#4-åŸºç¡€é…ç½®)
5. [åˆ›å»ºç¬¬ä¸€ä¸ªä»»åŠ¡](#5-åˆ›å»ºç¬¬ä¸€ä¸ªä»»åŠ¡)
6. [è¿è¡Œå’Œç›‘æ§](#6-è¿è¡Œå’Œç›‘æ§)
7. [é«˜çº§ç‰¹æ€§](#7-é«˜çº§ç‰¹æ€§)
8. [é”™è¯¯å¤„ç†](#8-é”™è¯¯å¤„ç†)
9. [æœ€ä½³å®è·µ](#9-æœ€ä½³å®è·µ)
10. [å¸¸è§é—®é¢˜](#10-å¸¸è§é—®é¢˜)

---

## 1. Celery ç®€ä»‹

### ä»€ä¹ˆæ˜¯ Celeryï¼Ÿ

Celery æ˜¯ä¸€ä¸ª**åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—**ï¼Œä¸“æ³¨äº**å®æ—¶å¤„ç†**å’Œ**ä»»åŠ¡è°ƒåº¦**ã€‚å®ƒæ˜¯ Python ç”Ÿæ€ç³»ç»Ÿä¸­æœ€é‡è¦çš„å¼‚æ­¥ä»»åŠ¡å¤„ç†æ¡†æ¶ä¹‹ä¸€ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦ Celeryï¼Ÿ

æƒ³è±¡è¿™ä¸ªåœºæ™¯ï¼š
```python
# ä¼ ç»ŸåŒæ­¥å¤„ç† - ç”¨æˆ·ä½“éªŒå·®
@app.post("/generate-image")
def generate_image(prompt):
    # å›¾ç‰‡ç”Ÿæˆéœ€è¦ 30 ç§’
    result = ai_service.generate_image(prompt)  # é˜»å¡ 30 ç§’ï¼
    return result  # ç”¨æˆ·éœ€è¦ç­‰å¾… 30 ç§’
```

```python
# ä½¿ç”¨ Celery å¼‚æ­¥å¤„ç† - ç”¨æˆ·ä½“éªŒå¥½
@app.post("/generate-image")
def generate_image(prompt):
    # ç«‹å³è¿”å›ä»»åŠ¡ ID
    task = ai_generate_image.delay(prompt)  # éé˜»å¡ï¼Œç«‹å³è¿”å›
    return {"task_id": task.id, "status": "PENDING"}  # ç”¨æˆ·ç«‹å³å¾—åˆ°å“åº”
```

### Celery çš„æ ¸å¿ƒä¼˜åŠ¿

- âœ… **å¼‚æ­¥å¤„ç†**: ä¸é˜»å¡ä¸»çº¿ç¨‹
- âœ… **åˆ†å¸ƒå¼**: å¤šä¸ª Worker å¹¶è¡Œå¤„ç†
- âœ… **å¯é æ€§**: ä»»åŠ¡å¤±è´¥è‡ªåŠ¨é‡è¯•
- âœ… **ç›‘æ§**: å®Œæ•´çš„ä»»åŠ¡çŠ¶æ€è·Ÿè¸ª
- âœ… **æ‰©å±•æ€§**: æ°´å¹³æ‰©å±• Worker æ•°é‡

---

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 åŸºæœ¬ç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    æ¶ˆæ¯    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    ä»»åŠ¡    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer  â”‚  ------>  â”‚    Broker   â”‚  ------>  â”‚   Consumer  â”‚
â”‚  (ç”Ÿäº§è€…)    â”‚           â”‚  (æ¶ˆæ¯é˜Ÿåˆ—)  â”‚           â”‚  (æ¶ˆè´¹è€…)    â”‚
â”‚  FastAPI     â”‚           â”‚   Redis     â”‚           â”‚  Celery     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       |                          |                           |
       |                          â†“                           â†“
       |                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       |                   â”‚    Queue    â”‚           â”‚    Worker    â”‚
       |                   â”‚  (ä»»åŠ¡é˜Ÿåˆ—)  â”‚           â”‚  (å·¥ä½œè¿›ç¨‹)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å…³é”®æœ¯è¯­è§£é‡Š

| æœ¯è¯­ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **Task** | è¦æ‰§è¡Œçš„å·¥ä½œå•å…ƒ | `send_email_task.delay()` |
| **Worker** | æ‰§è¡Œä»»åŠ¡çš„è¿›ç¨‹ | `celery worker -A app` |
| **Broker** | æ¶ˆæ¯ä¸­é—´ä»¶ï¼Œå­˜å‚¨ä»»åŠ¡ | Redisã€RabbitMQ |
| **Backend** | å­˜å‚¨ä»»åŠ¡ç»“æœçš„åœ°æ–¹ | Redisã€æ•°æ®åº“ |
| **Queue** | ä»»åŠ¡é˜Ÿåˆ—ï¼ŒæŒ‰ä¼˜å…ˆçº§åˆ†ç±» | `default`, `high_priority` |

### 2.3 æˆ‘ä»¬é¡¹ç›®ä¸­çš„ç»„ä»¶

åŸºäºå½“å‰ä»£ç ï¼š

```python
# ç”Ÿäº§è€…ï¼šFastAPI åº”ç”¨
@router.post("/tasks")
async def create_task(task_in: TaskCreate):
    task = await task_crud.create_task(db=db, obj_in=task_in)

    # è§¦å‘å¼‚æ­¥ä»»åŠ¡
    run_ai_text_generation.delay(  # ğŸ¯ è¿™é‡Œæ˜¯å…³é”®ï¼
        task_id=str(task.id),
        prompt=task.prompt,
        model=task.model
    )
    return task

# æ¶ˆæ¯é˜Ÿåˆ—ï¼šRedis
celery_broker_url = "redis://localhost:6379/1"

# æ¶ˆè´¹è€…ï¼šCelery Worker
celery -A app.worker worker --loglevel=info

# ä»»åŠ¡å®šä¹‰ï¼šAI æ–‡æœ¬ç”Ÿæˆ
@celery_app.task(bind=True, name="run_ai_text_generation")
def run_ai_text_generation(self, task_id: str, prompt: str, model: str):
    # å®é™…çš„ AI å¤„ç†é€»è¾‘
    pass
```

---

## 3. ç¯å¢ƒæ­å»º

### 3.1 å®‰è£…ä¾èµ–

åœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­ï¼Œä¾èµ–å·²ç»é…ç½®åœ¨ [`pyproject.toml`](pyproject.toml:19-21):

```toml
dependencies = [
    # ... å…¶ä»–ä¾èµ–
    "celery[redis]>=5.3.0",    # Celery æ ¸å¿ƒå’Œ Redis æ”¯æŒ
    "redis>=5.0.0",            # Redis Python å®¢æˆ·ç«¯
    "flower>=2.0.0",           # Celery ç›‘æ§å·¥å…·
]
```

**å®‰è£…å‘½ä»¤**ï¼š
```bash
# ä½¿ç”¨ uvï¼ˆæˆ‘ä»¬çš„é¡¹ç›®æ¨èï¼‰
uv sync

# æˆ–è€…ä½¿ç”¨ pip
pip install "celery[redis]>=5.3.0" "redis>=5.0.0" "flower>=2.0.0"
```

### 3.2 å¯åŠ¨ Redis æœåŠ¡

```bash
# ä½¿ç”¨ Docker å¯åŠ¨ Redisï¼ˆæ¨èï¼‰
docker run -d --name redis-ai-task -p 6379:6379 redis:7-alpine

# éªŒè¯ Redis è¿æ¥
docker exec redis-ai-task redis-cli ping
# åº”è¯¥è¿”å›: PONG
```

### 3.3 é¡¹ç›®ç»“æ„

æˆ‘ä»¬é‡‡ç”¨äº†æ¸…æ™°çš„æ¨¡å—åŒ–ç»“æ„ï¼š

```
app/
â”œâ”€â”€ worker/
â”‚   â”œâ”€â”€ __init__.py          # å¯¼å‡º celery_app
â”‚   â”œâ”€â”€ app.py              # ğŸ”‘ Celery åº”ç”¨é…ç½®
â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ai_tasks.py     # AI ç›¸å…³ä»»åŠ¡
â”‚       â””â”€â”€ demo_tasks.py   # æ¼”ç¤ºä»»åŠ¡
â”œâ”€â”€ api/v1/endpoints/
â”‚   â””â”€â”€ tasks.py            # ğŸ¯ FastAPI é›†æˆç‚¹
â”œâ”€â”€ crud/
â”‚   â””â”€â”€ task.py             # æ•°æ®åº“æ“ä½œ
â””â”€â”€ database.py             # åŒæ­¥/å¼‚æ­¥æ•°æ®åº“ä¼šè¯
```

---

## 4. åŸºç¡€é…ç½®

### 4.1 Celery åº”ç”¨é…ç½®

**æ–‡ä»¶ä½ç½®**: [`app/worker/app.py`](app/worker/app.py)

```python
from celery import Celery
from app.core.config import settings

# ğŸ”‘ åˆ›å»º Celery åº”ç”¨å®ä¾‹
celery_app = Celery(
    "async_ai_task_runner",              # åº”ç”¨åç§°
    broker=settings.celery_broker_url,  # æ¶ˆæ¯ä»£ç†
    backend=settings.celery_result_backend,  # ç»“æœå­˜å‚¨
    include=[                           # åŒ…å«çš„ä»»åŠ¡æ¨¡å—
        "app.worker.tasks.ai_tasks",
        "app.worker.tasks.demo_tasks"
    ]
)

# âš™ï¸ é«˜çº§é…ç½®
celery_app.conf.update(
    # åºåˆ—åŒ–é…ç½®
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,

    # ä»»åŠ¡è·¯ç”±é…ç½®
    task_routes={
        "app.worker.tasks.ai_tasks.*": {"queue": "ai_processing"},
        "app.worker.tasks.demo_tasks.*": {"queue": "demo_tasks"},
    },

    # æ€§èƒ½é…ç½®
    worker_prefetch_multiplier=1,
    task_acks_late=True,

    # ç»“æœè¿‡æœŸæ—¶é—´ï¼ˆ24å°æ—¶ï¼‰
    result_expires=3600,

    # ç›‘æ§é…ç½®
    worker_send_task_events=True,
    task_send_sent_event=True,
)
```

### 4.2 é…ç½®æ–‡ä»¶è¯´æ˜

| é…ç½®é¡¹ | è¯´æ˜ | æˆ‘ä»¬çš„å€¼ |
|--------|------|----------|
| `broker` | Redis è¿æ¥åœ°å€ | `redis://localhost:6379/1` |
| `backend` | ç»“æœå­˜å‚¨åœ°å€ | `redis://localhost:6379/2` |
| `task_serializer` | ä»»åŠ¡åºåˆ—åŒ–æ ¼å¼ | `json` |
| `timezone` | æ—¶åŒºè®¾ç½® | `UTC` |
| `task_routes` | ä»»åŠ¡è·¯ç”±è§„åˆ™ | æŒ‰ ç±»å‹ åˆ†ç»„ |

### 4.3 ç¯å¢ƒå˜é‡é…ç½®

**æ–‡ä»¶ä½ç½®**: [`app/core/config.py`](app/core/config.py:13-16)

```python
class Settings(BaseSettings):
    # Redis & Celery é…ç½®
    redis_url: str = "redis://localhost:6379/0"
    celery_broker_url: str = "redis://localhost:6379/1"      # ä»»åŠ¡é˜Ÿåˆ—
    celery_result_backend: str = "redis://localhost:6379/2"  # ç»“æœå­˜å‚¨
```

---

## 5. åˆ›å»ºç¬¬ä¸€ä¸ªä»»åŠ¡

### 5.1 ç®€å•ä»»åŠ¡å®šä¹‰

**æ–‡ä»¶ä½ç½®**: [`app/worker/tasks/demo_tasks.py`](app/worker/tasks/demo_tasks.py:11-25)

```python
from app.worker.app import celery_app
import time

@celery_app.task(name="simple_calculation")
def simple_calculation(a: int, b: int, operation: str = "add"):
    """
    ç®€å•çš„æ•°å­¦è®¡ç®—ä»»åŠ¡
    ç”¨äºæµ‹è¯• Celery åŸºæœ¬åŠŸèƒ½
    """
    print(f"ğŸ”¢ å¼€å§‹è®¡ç®—: {a} {operation} {b}")

    # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
    time.sleep(2)

    if operation == "add":
        result = a + b
    elif operation == "multiply":
        result = a * b
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œ: {operation}")

    print(f"âœ… è®¡ç®—ç»“æœ: {result}")

    return {
        "operation": f"{a} {operation} {b}",
        "result": result,
        "timestamp": time.time()
    }
```

### 5.2 å¸¦è¿›åº¦çš„ä»»åŠ¡

**æ–‡ä»¶ä½ç½®**: [`app/worker/tasks/ai_tasks.py`](app/worker/tasks/ai_tasks.py:12-55)

```python
from app.worker.app import celery_app
from app.models import TaskStatus
from app.crud.task import update_task_status, update_task_result
import time
import random

@celery_app.task(bind=True, name="run_ai_text_generation")
def run_ai_text_generation(self, task_id: str, prompt: str, model: str = "gpt-3.5-turbo"):
    """
    ğŸ¤– AI æ–‡æœ¬ç”Ÿæˆä»»åŠ¡
    æ”¯æŒè¿›åº¦è·Ÿè¸ªå’ŒçŠ¶æ€æ›´æ–°
    """
    try:
        print(f"ğŸ¤– å¼€å§‹å¤„ç†AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡: {task_id}")
        print(f"ğŸ“ Prompt: {prompt}")
        print(f"ğŸ§  Model: {model}")

        # 1. æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
        update_task_status(task_id, TaskStatus.PROCESSING)

        # 2. æ¨¡æ‹ŸAIå¤„ç†æ—¶é—´ï¼ˆ5-15ç§’ï¼‰
        processing_time = random.uniform(5, 15)
        print(f"â³ é¢„è®¡å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")

        # 3. ğŸ”‘ è¿›åº¦è·Ÿè¸ªï¼ˆè¿™æ˜¯é«˜çº§åŠŸèƒ½ï¼ï¼‰
        for i in range(int(processing_time)):
            time.sleep(1)
            progress = int((i + 1) / processing_time * 100)

            # æ›´æ–°ä»»åŠ¡è¿›åº¦
            self.update_state(
                state='PROGRESS',
                meta={
                    'current': i + 1,
                    'total': int(processing_time),
                    'progress': progress,
                    'status': f'å¤„ç†ä¸­... {progress}%'
                }
            )

        # 4. ç”ŸæˆAIç»“æœ
        if "å¤©æ°”" in prompt.lower():
            result = f"æ ¹æ®æ‚¨çš„é—®é¢˜'{prompt}'ï¼ŒAIåˆ†æï¼šä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cã€‚"
        elif "è®¡ç®—" in prompt.lower():
            result = f"AIæ•°å­¦åŠ©æ‰‹ï¼šé’ˆå¯¹'{prompt}'çš„è®¡ç®—ç»“æœæ˜¯42ã€‚"
        else:
            result = f"AIæ™ºèƒ½å›å¤ï¼šå…³äº'{prompt}'ï¼Œè¿™æ˜¯æˆ‘çš„æ·±åº¦åˆ†æ..."

        # 5. æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡ç»“æœ
        update_task_result(task_id, TaskStatus.COMPLETED, result)

        print(f"âœ… AIæ–‡æœ¬ç”Ÿæˆä»»åŠ¡å®Œæˆ: {task_id}")

        # 6. è¿”å›ç»“æœ
        return {
            'task_id': task_id,
            'status': 'completed',
            'result': result,
            'processing_time': processing_time
        }

    except Exception as e:
        error_msg = f"AIæ–‡æœ¬ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")

        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        update_task_result(task_id, TaskStatus.FAILED, error_msg)

        # ä»»åŠ¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸è®©Celeryé‡è¯•æœºåˆ¶ç”Ÿæ•ˆ
        raise self.retry(exc=e, countdown=60, max_retries=3)
```

### 5.3 ä»»åŠ¡è£…é¥°å™¨è¯¦è§£

```python
# åŸºç¡€ä»»åŠ¡è£…é¥°å™¨
@celery_app.task
def basic_task():
    pass

# å¸¦åç§°çš„ä»»åŠ¡ï¼ˆæ¨èï¼‰
@celery_app.task(name="my_custom_task_name")
def named_task():
    pass

# ç»‘å®šä»»åŠ¡å®ä¾‹ï¼ˆç”¨äºè¿›åº¦è·Ÿè¸ªï¼‰
@celery_app.task(bind=True)
def bound_task(self):
    # self åŒ…å«ä»»åŠ¡ä¿¡æ¯
    print(f"Task ID: {self.request.id}")
    print(f"Retry count: {self.request.retries}")

    # æ›´æ–°è¿›åº¦
    self.update_state(state='PROGRESS', meta={'progress': 50})

# å¸¦é‡è¯•çš„ä»»åŠ¡
@celery_app.task(bind=True, max_retries=3)
def retry_task(self):
    try:
        # å¯èƒ½å¤±è´¥çš„æ“ä½œ
        risky_operation()
    except Exception as exc:
        # é‡è¯•ï¼Œå»¶è¿Ÿ60ç§’
        raise self.retry(exc=exc, countdown=60)

# å¸¦ä¼˜å…ˆçº§çš„ä»»åŠ¡
@celery_app.task(priority=5)
def priority_task():
    pass
```

---

## 6. è¿è¡Œå’Œç›‘æ§

### 6.1 å¯åŠ¨ Celery Worker

```bash
# åŸºç¡€å¯åŠ¨å‘½ä»¤
celery -A app.worker worker --loglevel=info

# æŒ‡å®šå¹¶å‘æ•°ï¼ˆæ¨èï¼‰
celery -A app.worker worker --loglevel=info --concurrency=4

# å¯åŠ¨å¤šä¸ªWorkerè¿›ç¨‹
celery -A app.worker worker --loglevel=info --concurrency=2 &
celery -A app.worker worker --loglevel=info --concurrency=2 &

# å¯åŠ¨ç‰¹å®šé˜Ÿåˆ—çš„Worker
celery -A app.worker worker --loglevel=info --queues=ai_processing

# åå°è¿è¡Œï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
celery -A app.worker worker --loglevel=info --detach
```

### 6.2 ç›‘æ§å·¥å…·ï¼šFlower

```bash
# å¯åŠ¨ Flower ç›‘æ§é¢æ¿
celery -A app.worker flower --port=5555

# è®¿é—®ç›‘æ§ç•Œé¢
# http://localhost:5555
```

**Flower åŠŸèƒ½**ï¼š
- ğŸ“Š å®æ—¶ä»»åŠ¡ç»Ÿè®¡
- ğŸ‘¥ Worker çŠ¶æ€ç›‘æ§
- ğŸ“ˆ ä»»åŠ¡æ‰§è¡Œå†å²
- ğŸ”§ ä»»åŠ¡ç®¡ç†ï¼ˆé‡è¯•ã€æ’¤é”€ç­‰ï¼‰

### 6.3 å‘½ä»¤è¡Œç®¡ç†

```bash
# æŸ¥çœ‹æ´»åŠ¨ä»»åŠ¡
celery -A app.worker inspect active

# æŸ¥çœ‹æ³¨å†Œçš„ä»»åŠ¡
celery -A app.worker inspect registered

# æŸ¥çœ‹Workerç»Ÿè®¡ä¿¡æ¯
celery -A app.worker inspect stats

# æŸ¥çœ‹é˜Ÿåˆ—é•¿åº¦
# éœ€è¦ redis-cli
docker exec redis-ai-task redis-cli llen celery
```

### 6.4 ä»£ç ä¸­çš„ä»»åŠ¡è°ƒç”¨

```python
# ğŸ¯ ç›´æ¥è°ƒç”¨ï¼ˆæ¨èï¼‰
from app.worker.tasks.demo_tasks import simple_calculation

# ç«‹å³å¼‚æ­¥æ‰§è¡Œ
result = simple_calculation.delay(10, 20, "add")
print(f"ä»»åŠ¡ID: {result.id}")

# ç­‰å¾…ç»“æœ
if result.ready():
    print(f"ç»“æœ: {result.get()}")

# è®¾ç½®è¶…æ—¶
try:
    result = result.get(timeout=10)
except Exception as e:
    print(f"ä»»åŠ¡è¶…æ—¶æˆ–å¤±è´¥: {e}")

# è·å–ä»»åŠ¡çŠ¶æ€
print(f"çŠ¶æ€: {result.status}")
print(f"ç»“æœ: {result.result}")

# å–æ¶ˆä»»åŠ¡
result.revoke(terminate=True)
```

---

## 7. é«˜çº§ç‰¹æ€§

### 7.1 ä»»åŠ¡è·¯ç”±

**é…ç½®**: [`app/worker/app.py`](app/worker/app.py:24-30)

```python
celery_app.conf.update(
    task_routes={
        "app.worker.tasks.ai_tasks.*": {"queue": "ai_processing"},
        "app.worker.tasks.demo_tasks.*": {"queue": "demo_tasks"},
        "app.worker.tasks.urgent.*": {"queue": "urgent"},
    }
)
```

**ä½¿ç”¨**ï¼š
```bash
# å¯åŠ¨ä¸“é—¨å¤„ç†AIä»»åŠ¡çš„Worker
celery -A app.worker worker --queues=ai_processing --concurrency=2

# å¯åŠ¨ä¸“é—¨å¤„ç†ç´§æ€¥ä»»åŠ¡çš„Worker
celery -A app.worker worker --queues=urgent --concurrency=1
```

### 7.2 ä»»åŠ¡é“¾ (Chain)

```python
from celery import chain

# å®šä¹‰ä»»åŠ¡é“¾
task_chain = chain(
    process_data.s(raw_data),
    analyze_results.s(),
    generate_report.s()
)

# æ‰§è¡Œä»»åŠ¡é“¾
result = task_chain()
print(f"æœ€ç»ˆç»“æœ: {result.get()}")
```

### 7.3 ä»»åŠ¡ç»„ (Group)

```python
from celery import group

# å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡
job = group([
    process_item.s(item) for item in items
])

# æ‰§è¡Œä»»åŠ¡ç»„
result = job()
print(f"æ‰€æœ‰ç»“æœ: {result.get()}")
```

### 7.4 å®šæ—¶ä»»åŠ¡ (Beat)

```python
from celery.schedules import crontab

# é…ç½®å®šæ—¶ä»»åŠ¡
celery_app.conf.beat_schedule = {
    'daily-cleanup': {
        'task': 'cleanup_old_tasks',
        'schedule': crontab(hour=2, minute=0),  # æ¯å¤©å‡Œæ™¨2ç‚¹
    },
    'hourly-stats': {
        'task': 'generate_hourly_stats',
        'schedule': crontab(minute=0),  # æ¯å°æ—¶
    },
}
```

**å¯åŠ¨ Beat è°ƒåº¦å™¨**ï¼š
```bash
celery -A app.worker beat --loglevel=info
```

### 7.5 ä»»åŠ¡ä¼˜å…ˆçº§

```python
# å®šä¹‰é«˜ä¼˜å…ˆçº§ä»»åŠ¡
@celery_app.task(priority=9)
def high_priority_task():
    pass

# å®šä¹‰ä½ä¼˜å…ˆçº§ä»»åŠ¡
@celery_app.task(priority=1)
def low_priority_task():
    pass

# Worker é…ç½®æ”¯æŒä¼˜å…ˆçº§
celery -A app.worker worker --loglevel=info -Ofair
```

---

## 8. é”™è¯¯å¤„ç†

### 8.1 å¼‚å¸¸å¤„ç†æ¨¡å¼

**æ–‡ä»¶ä½ç½®**: [`app/worker/tasks/ai_tasks.py`](app/worker/tasks/ai_tasks.py:52-65)

```python
@celery_app.task(bind=True, max_retries=3)
def robust_task(self, data):
    try:
        # å¯èƒ½å¤±è´¥çš„æ“ä½œ
        result = process_data(data)
        return result
    except ConnectionError as exc:
        # ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•
        raise self.retry(exc=exc, countdown=60)
    except ValueError as exc:
        # æ•°æ®é”™è¯¯ï¼Œä¸é‡è¯•ï¼Œç›´æ¥å¤±è´¥
        raise exc
    except Exception as exc:
        # å…¶ä»–é”™è¯¯ï¼Œé‡è¯•
        raise self.retry(exc=exc, countdown=60)
```

### 8.2 é‡è¯•ç­–ç•¥

```python
# æŒ‡æ•°é€€é¿é‡è¯•
@celery_app.task(bind=True, max_retries=5)
def exponential_backoff_task(self):
    try:
        risky_operation()
    except Exception as exc:
        # 2^retry_count å»¶è¿Ÿ
        countdown = 2 ** self.request.retries
        raise self.retry(exc=exc, countdown=countdown)

# å›ºå®šå»¶è¿Ÿé‡è¯•
@celery_app.task(bind=True, max_retries=3)
def fixed_delay_task(self):
    try:
        risky_operation()
    except Exception as exc:
        # å›ºå®šå»¶è¿Ÿ60ç§’
        raise self.retry(exc=exc, countdown=60)
```

### 8.3 ä»»åŠ¡è¶…æ—¶

```python
# ä»»åŠ¡çº§åˆ«è¶…æ—¶
@celery_app.task(time_limit=300)  # 5åˆ†é’Ÿè¶…æ—¶
def long_running_task():
    pass

# åº”ç”¨çº§åˆ«è¶…æ—¶é…ç½®
celery_app.conf.update(
    task_soft_time_limit=240,  # è½¯è¶…æ—¶ï¼ˆ4åˆ†é’Ÿï¼‰
    task_time_limit=300,       # ç¡¬è¶…æ—¶ï¼ˆ5åˆ†é’Ÿï¼‰
)
```

### 8.4 ç»“æœåå¤„ç†

```python
@celery_app.task(bind=True)
def task_with_callback(self, data):
    result = process_data(data)

    # ä»»åŠ¡å®Œæˆåæ‰§è¡Œå›è°ƒ
    if result:
        on_success.delay(result)
    else:
        on_failure.delay(data)

    return result

@celery_app.task
def on_success(result):
    print(f"ä»»åŠ¡æˆåŠŸ: {result}")

@celery_app.task
def on_failure(data):
    print(f"ä»»åŠ¡å¤±è´¥ï¼Œé‡æ–°è°ƒåº¦: {data}")
    retry_task.delay(data)
```

---

## 9. æœ€ä½³å®è·µ

### 9.1 ä»»åŠ¡è®¾è®¡åŸåˆ™

```python
# âœ… å¥½çš„ä»»åŠ¡è®¾è®¡
@celery_app.task(bind=True, max_retries=3)
def well_designed_task(self, data):
    """
    è®¾è®¡è‰¯å¥½çš„ä»»åŠ¡
    """
    # 1. å‚æ•°éªŒè¯
    if not data:
        raise ValueError("æ•°æ®ä¸èƒ½ä¸ºç©º")

    # 2. å¹‚ç­‰æ€§æ£€æŸ¥
    if already_processed(data['id']):
        return get_existing_result(data['id'])

    try:
        # 3. åŸå­æ€§æ“ä½œ
        result = process_data(data)
        save_result(data['id'], result)
        return result
    except Exception as exc:
        # 4. é€‚å½“çš„é”™è¯¯å¤„ç†
        logger.error(f"ä»»åŠ¡å¤„ç†å¤±è´¥: {exc}")
        raise self.retry(exc=exc, countdown=60)

# âŒ é¿å…çš„ä»»åŠ¡è®¾è®¡
@celery_app.task
def bad_task():
    # 1. å…¨å±€çŠ¶æ€ä¾èµ–
    global some_global_var

    # 2. é•¿æ—¶é—´è¿è¡Œï¼ˆæ— è¶…æ—¶ï¼‰
    while True:
        pass

    # 3. æ²¡æœ‰é”™è¯¯å¤„ç†
    risky_operation()

    # 4. ä¸å¹‚ç­‰
    send_email()
```

### 9.2 æ€§èƒ½ä¼˜åŒ–

```python
# 1. æ‰¹é‡å¤„ç†
@celery_app.task
def batch_process(items):
    """æ‰¹é‡å¤„ç†å¤šä¸ªé¡¹ç›®"""
    for item in items:
        process_item(item)
    return len(items)

# 2. ä»»åŠ¡åˆ†ç‰‡
def process_large_dataset(data):
    """å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå°ä»»åŠ¡"""
    chunk_size = 100
    chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]

    # å¹¶è¡Œå¤„ç†æ‰€æœ‰å—
    job = group(batch_process.s(chunk) for chunk in chunks)
    return job()

# 3. é¢„å–ä¼˜åŒ–
# Worker å¯åŠ¨å‚æ•°
# celery -A app.worker worker --prefetch-multiplier=1

# 4. è¿æ¥æ± ä¼˜åŒ–
celery_app.conf.update(
    broker_pool_limit=10,
    broker_connection_timeout=30,
)
```

### 9.3 ç›‘æ§å’Œæ—¥å¿—

```python
import logging
from celery.utils.log import get_task_logger

logger = get_task_logger(__name__)

@celery_app.task(bind=True)
def monitored_task(self, data):
    logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {self.request.id}")
    logger.info(f"æ•°æ®å¤§å°: {len(data)}")

    try:
        result = process_data(data)
        logger.info(f"ä»»åŠ¡å®Œæˆ {self.request.id}")
        return result
    except Exception as exc:
        logger.error(f"ä»»åŠ¡å¤±è´¥ {self.request.id}: {exc}")
        raise

# é…ç½®æ—¥å¿—
celery_app.conf.update(
    worker_log_format='[%(asctime)s: %(levelname)s/%(processName)s] %(message)s',
    worker_task_log_format='[%(asctime)s: %(levelname)s/%(processName)s][%(task_name)s(%(task_id)s)] %(message)s',
)
```

### 9.4 ç”Ÿäº§ç¯å¢ƒé…ç½®

```python
# ç”Ÿäº§ç¯å¢ƒé…ç½®
celery_app.conf.update(
    # å¯é æ€§é…ç½®
    task_acks_late=True,
    worker_prefetch_multiplier=1,
    task_reject_on_worker_lost=True,

    # æ€§èƒ½é…ç½®
    worker_disable_rate_limits=False,
    task_compression='gzip',

    # å®‰å…¨é…ç½®
    broker_transport_options={
        'visibility_timeout': 3600,  # 1å°æ—¶
        'retry_policy': {
            'timeout': 5.0
        }
    }
)

# å¯åŠ¨å‘½ä»¤ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
# celery -A app.worker worker --loglevel=info --concurrency=4 --max-tasks-per-child=1000
```

---

## 10. å¸¸è§é—®é¢˜

### 10.1 ä»»åŠ¡ä¸æ‰§è¡Œ

**é—®é¢˜**: ä»»åŠ¡æäº¤åæ²¡æœ‰æ‰§è¡Œ

**æ’æŸ¥æ­¥éª¤**:
```bash
# 1. æ£€æŸ¥WorkerçŠ¶æ€
celery -A app.worker inspect active

# 2. æ£€æŸ¥é˜Ÿåˆ—é•¿åº¦
docker exec redis-ai-task redis-cli llen celery

# 3. æ£€æŸ¥Workeræ—¥å¿—
# æŸ¥çœ‹Workerè¾“å‡ºï¼Œçœ‹æ˜¯å¦æœ‰é”™è¯¯

# 4. æ£€æŸ¥ä»»åŠ¡æ³¨å†Œ
celery -A app.worker inspect registered
```

### 10.2 æ•°æ®åº“è¿æ¥é—®é¢˜

**é—®é¢˜**: Celery ä»»åŠ¡ä¸­æ•°æ®åº“è¿æ¥å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```python
# âœ… ä½¿ç”¨åŒæ­¥æ•°æ®åº“ä¼šè¯
from app.database import get_sync_db_session

@celery_app.task
def db_task():
    with get_sync_db_session() as db:
        # åŒæ­¥æ•°æ®åº“æ“ä½œ
        result = db.query(Task).first()
    return result
```

### 10.3 å†…å­˜æ³„æ¼

**é—®é¢˜**: Worker å†…å­˜æŒç»­å¢é•¿

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é™åˆ¶æ¯ä¸ªWorkerå¤„ç†çš„ä»»åŠ¡æ•°
celery -A app.worker worker --max-tasks-per-child=1000

# å®šæœŸé‡å¯Worker
# ä½¿ç”¨supervisorç­‰è¿›ç¨‹ç®¡ç†å·¥å…·
```

### 10.4 ä»»åŠ¡é‡å¤æ‰§è¡Œ

**é—®é¢˜**: ç›¸åŒä»»åŠ¡è¢«æ‰§è¡Œå¤šæ¬¡

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿ä»»åŠ¡å¹‚ç­‰æ€§
@celery_app.task
def idempotent_task(unique_id):
    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if is_processed(unique_id):
        return get_result(unique_id)

    # å¤„ç†ä»»åŠ¡
    result = process_task(unique_id)

    # æ ‡è®°å·²å¤„ç†
    mark_processed(unique_id, result)

    return result
```

### 10.5 æ€§èƒ½é—®é¢˜

**é—®é¢˜**: ä»»åŠ¡æ‰§è¡Œå¤ªæ…¢

**ä¼˜åŒ–å»ºè®®**:
```python
# 1. åˆ†æä»»åŠ¡ç“¶é¢ˆ
@celery_app.task(bind=True)
def profile_task(self, data):
    import cProfile
    import io

    pr = cProfile.Profile()
    pr.enable()

    result = expensive_operation(data)

    pr.disable()
    s = io.StringIO()
    ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')
    ps.print_stats()

    logger.info(f"æ€§èƒ½åˆ†æ:\n{s.getvalue()}")
    return result
```

---

## ğŸ¯ æ€»ç»“

é€šè¿‡è¿™ä¸ªæ•™ç¨‹ï¼Œæ‚¨å·²ç»å­¦ä¼šäº†ï¼š

1. âœ… **Celery åŸºç¡€æ¦‚å¿µ**: ç†è§£äº† Producer-Consumer æ¨¡å¼
2. âœ… **ç¯å¢ƒæ­å»º**: é…ç½®äº† Redis å’Œ Celery åº”ç”¨
3. âœ… **ä»»åŠ¡åˆ›å»º**: ç¼–å†™äº†å„ç§ç±»å‹çš„ä»»åŠ¡
4. âœ… **è¿è¡Œç›‘æ§**: å¯åŠ¨ Worker å’Œ Flower ç›‘æ§
5. âœ… **é«˜çº§ç‰¹æ€§**: è·¯ç”±ã€é‡è¯•ã€è¿›åº¦è·Ÿè¸ª
6. âœ… **é”™è¯¯å¤„ç†**: å¼‚å¸¸æ•è·å’Œé‡è¯•æœºåˆ¶
7. âœ… **æœ€ä½³å®è·µ**: æ€§èƒ½ä¼˜åŒ–å’Œç”Ÿäº§é…ç½®

### ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®

1. **æ·±å…¥å­¦ä¹ **: é˜…è¯» [Celery å®˜æ–¹æ–‡æ¡£](https://docs.celeryproject.org/)
2. **å®è·µé¡¹ç›®**: å°è¯•å®ç°é‚®ä»¶å‘é€ã€å›¾åƒå¤„ç†ç­‰å®é™…åœºæ™¯
3. **æ€§èƒ½è°ƒä¼˜**: æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´é…ç½®å‚æ•°
4. **ç›‘æ§é›†æˆ**: é›†æˆ Prometheusã€Grafana ç­‰ç›‘æ§å·¥å…·

### æˆ‘ä»¬é¡¹ç›®ä¸­çš„å®Œæ•´å®ç°

å½“å‰é¡¹ç›®åŒ…å«äº†ä¸€ä¸ªå®Œæ•´çš„ Celery å®ç°ï¼š

- ğŸ“ **é…ç½®**: [`app/worker/app.py`](app/worker/app.py) - å®Œæ•´çš„ Celery é…ç½®
- ğŸ”§ **ä»»åŠ¡**: [`app/worker/tasks/`](app/worker/tasks/) - AI ä»»åŠ¡å’Œæ¼”ç¤ºä»»åŠ¡
- ğŸŒ **é›†æˆ**: [`app/api/v1/endpoints/tasks.py`](app/api/v1/endpoints/tasks.py) - FastAPI é›†æˆ
- ğŸ’¾ **æ•°æ®**: [`app/crud/task.py`](app/crud/task.py) - æ•°æ®åº“æ“ä½œ
- ğŸ§ª **æµ‹è¯•**: [`quick_test.py`](quick_test.py) - åŠŸèƒ½éªŒè¯

è¿™å·²ç»æ˜¯ä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„ Celery å®ç°ï¼Œå¯ä»¥ç›´æ¥ä½œä¸ºå‚è€ƒå’Œå­¦ä¹ ææ–™ï¼ğŸš€